{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d021d270",
   "metadata": {},
   "source": [
    "##Assignment 1: LLM Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff34e3",
   "metadata": {},
   "source": [
    "\n",
    "**Encoder-only models** (e.g., **BERT**) are designed for understanding and classification tasks by encoding text into contextual representations.  \n",
    "**Decoder-only models** (e.g., **GPT**) are generative, predicting the next token to produce coherent text.  \n",
    "**Encoder-decoder models** (e.g., **T5, BART**) combine both: the encoder understands input, and the decoder generates output.  \n",
    "\n",
    "- Example usage:  \n",
    "  - Encoder-only → Sentiment analysis  \n",
    "  - Decoder-only → Chatbots/text generation  \n",
    "  - Encoder-decoder → Machine translation  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5eb7b",
   "metadata": {},
   "source": [
    "## Assignment 2: STT/TTS Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794a183",
   "metadata": {},
   "source": [
    "\n",
    "- **STT Model**: **DeepSpeech (by Mozilla)**  \n",
    "  - What it does: Converts spoken audio into text.  \n",
    "  - Application: Transcribing lectures for students.  \n",
    "\n",
    "- **TTS Model**: **Tacotron 2 (by Google)**  \n",
    "  - What it does: Generates natural, human-like speech from text.  \n",
    "  - Application: Audiobook narration.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0f570",
   "metadata": {},
   "source": [
    "## Assignment 3: Build a Chatbot with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api.groq.com/v1/chat/completions\"\n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "\n",
    "def chatbot():\n",
    "    memory = []\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"quit\":\n",
    "            break\n",
    "        \n",
    "        memory.append({\"role\": \"user\", \"content\": user_input})\n",
    "        memory = memory[-5:]  # Keep last 5 messages\n",
    "\n",
    "        response = requests.post(API_URL, json={\n",
    "            \"model\": \"mixtral-8x7b-32768\",\n",
    "            \"messages\": memory\n",
    "        }, headers=headers)\n",
    "\n",
    "        reply = response.json()['choices'][0]['message']['content']\n",
    "        print(\"Bot:\", reply)\n",
    "\n",
    "        memory.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "chatbot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2ac2b",
   "metadata": {},
   "source": [
    "## Assignment 4: Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9c6cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are you\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
    "    text = \" \".join(text.split())  # remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "print(clean_text(\"  HELLo!!!  How ARE you?? \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4eca0",
   "metadata": {},
   "source": [
    "## Assignment 5: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc722e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation & numbers\n",
    "    text = ''.join([ch for ch in text if ch.isalpha() or ch.isspace()])\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]\n",
    "    # Remove short words (<3 chars)\n",
    "    words = [w for w in words if len(w) >= 3]\n",
    "    # POS tagging – keep nouns, verbs, adjectives\n",
    "    allowed_tags = {\"NN\", \"NNS\", \"NNP\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"JJ\", \"JJR\", \"JJS\"}\n",
    "    tagged = pos_tag(words)\n",
    "    words = [w for w, t in tagged if t in allowed_tags]\n",
    "    \n",
    "    return words\n",
    "\n",
    "# Example\n",
    "print(preprocess(\"Cats are running quickly in the garden with 123 flowers.\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeeea7f",
   "metadata": {},
   "source": [
    "## Assignment 6: Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c263e87",
   "metadata": {},
   "source": [
    "\n",
    "- **Context memory** is important in chatbots because it allows them to maintain conversation flow, understand references to previous messages, and give more natural and relevant responses.  \n",
    "- **Checking API limits and pricing** helps beginners avoid unexpected costs and ensures their projects remain scalable and affordable.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
